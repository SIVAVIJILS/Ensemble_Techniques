{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f74dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To plot all the diagrams within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dfc88a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeb76326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#calculate accuracy measures and confusion matrix\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "367b800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca568a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df=pd.read_csv(\"D:\\Machine Learning\\Machine Learning Projects\\Ensemble-Bagging(Decision Tree)\\credit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "046dd225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 17 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   checking_balance      1000 non-null   object\n",
      " 1   months_loan_duration  1000 non-null   int64 \n",
      " 2   credit_history        1000 non-null   object\n",
      " 3   purpose               1000 non-null   object\n",
      " 4   amount                1000 non-null   int64 \n",
      " 5   savings_balance       1000 non-null   object\n",
      " 6   employment_duration   1000 non-null   object\n",
      " 7   percent_of_income     1000 non-null   int64 \n",
      " 8   years_at_residence    1000 non-null   int64 \n",
      " 9   age                   1000 non-null   int64 \n",
      " 10  other_credit          1000 non-null   object\n",
      " 11  housing               1000 non-null   object\n",
      " 12  existing_loans_count  1000 non-null   int64 \n",
      " 13  job                   1000 non-null   object\n",
      " 14  dependents            1000 non-null   int64 \n",
      " 15  phone                 1000 non-null   object\n",
      " 16  default               1000 non-null   object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 132.9+ KB\n"
     ]
    }
   ],
   "source": [
    "credit_df.info()#info-it gives the structure of the data frame\n",
    "\n",
    "#many columns are of the type object,i.e. strings. These need to be converted to a numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f249b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the \"object\" or \"string\" datatypes to a numeric or categorical datatypes\n",
    "\n",
    "# Decision tree in python can take only nemerical/categorical columns .It cannot take string/object\n",
    "# The following code loops through each column and checks if the column type is object, then converts those...\n",
    "#... into categorical with each distinct value becoming a category or code.\n",
    "\n",
    "for feature in credit_df.columns: # loop through all columns in the data frame\n",
    "    if credit_df[feature].dtype=='object': # only apply for columns with categorical strings\n",
    "        credit_df[feature]= pd.Categorical(credit_df[feature]).codes # Replace strings with an integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9afbf6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 17 columns):\n",
      " #   Column                Non-Null Count  Dtype\n",
      "---  ------                --------------  -----\n",
      " 0   checking_balance      1000 non-null   int8 \n",
      " 1   months_loan_duration  1000 non-null   int64\n",
      " 2   credit_history        1000 non-null   int8 \n",
      " 3   purpose               1000 non-null   int8 \n",
      " 4   amount                1000 non-null   int64\n",
      " 5   savings_balance       1000 non-null   int8 \n",
      " 6   employment_duration   1000 non-null   int8 \n",
      " 7   percent_of_income     1000 non-null   int64\n",
      " 8   years_at_residence    1000 non-null   int64\n",
      " 9   age                   1000 non-null   int64\n",
      " 10  other_credit          1000 non-null   int8 \n",
      " 11  housing               1000 non-null   int8 \n",
      " 12  existing_loans_count  1000 non-null   int64\n",
      " 13  job                   1000 non-null   int8 \n",
      " 14  dependents            1000 non-null   int64\n",
      " 15  phone                 1000 non-null   int8 \n",
      " 16  default               1000 non-null   int8 \n",
      "dtypes: int64(7), int8(10)\n",
      "memory usage: 64.6 KB\n"
     ]
    }
   ],
   "source": [
    "#again checking the structure of the data frame\n",
    "credit_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "173ff5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing the ensemble score or performance with a simple one instance algorithm\n",
    "\n",
    "#splitting data into training and test set for independent attributes\n",
    "\n",
    "#**always use random function to split the data into training and test set**\n",
    "\n",
    "train_set=credit_df.head(700) # upto the last initial training set row\n",
    "test_set=credit_df.tail(300) # past the last initial training set row\n",
    "\n",
    "#capture the target column (\"default\") into separate vectors for training set and test set\n",
    "\n",
    "train_labels=train_set.pop(\"default\")\n",
    "test_labels=test_set.pop(\"default\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc3797a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoking the decision tree classifier function.Using 'entropy' method of finding the split columns\n",
    "#can use gini index also. \n",
    "#dt_model =DecisionTreeClassifier(criterion='entropy',max_depth=5,random_state=100)\n",
    "\n",
    "dt_model=DecisionTreeClassifier(criterion='entropy') #since we didn't use any regularization parameters like max_depth here,this decision tree will going to be 'overfit'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "409fee43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit function\n",
    "dt_model.fit(train_set,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "020dcb27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model.score(test_set, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11d3bfc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model.score(train_set,train_labels) # overfit due to large complexe tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebcca280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets use ENSEMBLE TECHNIQUE- BAGGING -To improve the model\n",
    "\n",
    "credit_labels=credit_df.pop(\"default\") # for ensemble you dont need training & test set\n",
    "                                       # Bagging can use out of bag records for testing\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1299b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble_score_for_OutOfBag_datasets = 0.745\n"
     ]
    }
   ],
   "source": [
    "# In the following lines,we call the bagging classifier with oob_score(out of bag_score),set to True ,which was False by default\n",
    "# This makes the baggingclassifier use the 37% unused data for testing\n",
    "#compare the performance of the Bagging classifier with the regularized decision tree above.\n",
    "#Though not required, you can keep separate test data (outside the bootstrap sampling)on which we test the Bagging Classifier. \n",
    "\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bgcl=BaggingClassifier(n_estimators=50 ,max_samples=.8,oob_score=True) # n_estimators=50(no reason)\n",
    "# max_samples=0.8--> of the 100% records in the original data frame,use only 80% to create your data sets for the ensemble\n",
    "# oob_score = True--> for ruuning the ensemble against the out of bag data set and see the performance \n",
    "\n",
    "bgcl=bgcl.fit(credit_df, credit_labels)\n",
    "print(\"Ensemble_score_for_OutOfBag_datasets =\" ,bgcl.oob_score_) #.oob_score_--> function which returns the result of testing your ensemble against the out of bag data sets\n",
    "                                                                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40e3688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing the score of the ensemble for the collection of 50 instances & the score of one instance ,i.e (0.74 & 0.693)\n",
    "#(0.74 > 0.693)-so ,there is a significant improvement in the ensemble compared to the one instance of a very large Deci tre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "692d85b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets REGULARAIZE the decision tree and check the performance\n",
    "\n",
    "dt_regularaized=DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=5)\n",
    "#min_samples_leaf=5--> at leaf level node ,there should be 5 records or more(not less)\n",
    "\n",
    "dt_regularaized.fit(train_set,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d7f187a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_score =  0.7828571428571428\n",
      "test_score =  0.7233333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"training_score = \", dt_regularaized.score(train_set,train_labels))\n",
    "print(\"test_score = \", dt_regularaized.score(test_set,test_labels)) #Relatively less overfit as training and test error are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "727fd618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here the score for test data (0.723) is lesser than the score for ensemble out of bag data sets(0.74)\n",
    "# so ensemble gave better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaa9e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ca5b256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENSEMBLE-BOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "245b7357",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENSEMBLE LEARNING --ADA BOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32094cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(criterion='entropy'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abcl= AdaBoostClassifier(base_estimator = dt_model , n_estimators = 50)#base_estimator = any classification algorithms\n",
    "                                                                                         #default= decision tree\n",
    "#abcl= AdaBoostClassifier(n_estimators=50)\n",
    "abcl.fit(train_set,train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "672b0ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = abcl.predict(test_set) # ***Every records in the test set will go through all the 50 trees and predict its own....\n",
    "                                   #...classification and we will take its majority vote***\n",
    "\n",
    "abcl.score(test_set , test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f4ee60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cf85300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENSEMBLE LEARNING --GRADIENT BOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0257ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(n_estimators=50)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#gbcl=GradientBoostingClassifier(n_estimators = 50 ,learning_rate = 0.09 , max_depth = 5)\n",
    "gbcl=GradientBoostingClassifier(n_estimators = 50)\n",
    "\n",
    "gbcl.fit(train_set,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00298d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7566666666666667"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = gbcl.predict(test_set)\n",
    "gbcl.score(test_set,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bbbdc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18147abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENSEMBLE-RANDOMFOREST CLASSIFIER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63bd5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfcl=RandomForestClassifier(n_estimators=6) #n_estimators(no.of tree)=6(different trees) --all this 6 trees will do different kind of errors \n",
    "rfcl=rfcl.fit(train_set,train_labels)\n",
    "\n",
    "#shift but.+ 2*tab but.--> to see the various parameters that are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b175c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7133333333333334"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred=rfcl.predict(test_set)\n",
    "rfcl.score(test_set,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48582b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#*** Ensemble models is a black box technique because we dont know internally how to interpret the model***.\n",
    "#*** Simple models is a white box technique***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76607325",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
